# 3. Rancher 클러스터 구축

## 3.1. 스크립트 파일 작성하기

이 가이드에서는 스크립트 파일에 작성해야 할 내용만을 언급합니다. 실제 세션에서 스크립트의 세부 구성 사항에 대한 설명을 별도로 진행합니다.

### main.tf 파일

```hcl
variable arm-prefix {
  default = "rkttu-rke"
}

variable dns-prefix {
  default = "rktturke"
}

variable vm-names {
  type = "list"
  default = [
    "controlplane",
    "etcd",
    "worker1",
    "worker2",
    "worker3"
  ]
}

variable vm-roles {
  type = "list"
  default = [
    "controlplane",
    "etcd",
    "worker",
    "worker",
    "worker"
  ]
}

variable vm-admin-username {
  default = "rkttu"
}

variable vm-admin-password {
  default = "rhksflwk949!"
}

data "template_file" "docker-deploy-script" {
  template = "${file("docker-deploy-script.tpl")}"
  vars {
    vm_admin_username = "${var.vm-admin-username}"
  }
}

# *********************** RKE CLUSTER *********************** #
resource "azurerm_resource_group" "rke-group" {
  name = "${var.arm-prefix}-group"
  location = "japaneast"
}

# ********************** VNET / SUBNET ********************** #
resource "azurerm_virtual_network" "rke-vnet" {
  name = "${var.arm-prefix}-vnet"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  location = "${azurerm_resource_group.rke-group.location}"
  address_space = ["10.0.0.0/16"]
}

resource "azurerm_subnet" "rke-subnet" {
  name = "${var.arm-prefix}-subnet"
  virtual_network_name = "${azurerm_virtual_network.rke-vnet.name}"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  network_security_group_id = "${azurerm_network_security_group.rke-secgroup.id}"
  address_prefix = "10.0.1.0/24"
  depends_on = ["azurerm_virtual_network.rke-vnet"]
}

# **********************  STORAGE ACCOUNTS ********************** #
resource "azurerm_storage_account" "rke-storage" {
  name = "rkestore"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  location = "${azurerm_resource_group.rke-group.location}"
  account_tier = "Standard"
  account_replication_type = "LRS"
}

# **********************  NETWORK SECURITY GROUP ********************** #
resource "azurerm_network_security_group" "rke-secgroup" {
  name = "${var.arm-prefix}-secgroup"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  location = "${azurerm_resource_group.rke-group.location}"

  security_rule {
    name = "allow-ssh"
    description = "Secure Shell"
    priority = 100
    direction = "Inbound"
    access = "Allow"
    protocol = "Tcp"
    source_port_range = "*"
    destination_port_range = "22"
    source_address_prefix = "*"
    destination_address_prefix = "*"
  }

  security_rule {
    name = "rke-cluster-1"
    description = "Kubernetes Communication Port 1"
    priority = 110
    direction = "Inbound"
    access = "Allow"
    protocol = "Tcp"
    source_port_range = "*"
    destination_port_range = "6443"
    source_address_prefix = "*"
    destination_address_prefix = "*"
  }

  security_rule {
    name = "rke-cluster-2"
    description = "Kubernetes Communication Port 2"
    priority = 120
    direction = "Inbound"
    access = "Allow"
    protocol = "Tcp"
    source_port_range = "*"
    destination_port_range = "2379"
    source_address_prefix = "*"
    destination_address_prefix = "*"
  }

  security_rule {
    name = "rke-cluster-3"
    description = "Kubernetes Communication Port 3"
    priority = 130
    direction = "Inbound"
    access = "Allow"
    protocol = "Tcp"
    source_port_range = "*"
    destination_port_range = "2380"
    source_address_prefix = "*"
    destination_address_prefix = "*"
  }
}

# **********************  PUBLIC IP ADDRESSES ********************** #
resource "azurerm_public_ip" "rke-public-ip" {
  name = "${var.arm-prefix}-public-ip"
  location = "${azurerm_resource_group.rke-group.location}"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  public_ip_address_allocation = "Static"
  domain_name_label = "${var.dns-prefix}"
}

# **********************  AVAILABILITY SET ********************** #
resource "azurerm_availability_set" "rke-availability-set" {
  name = "${var.arm-prefix}-set"
  location = "${azurerm_resource_group.rke-group.location}"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  managed = true
  
  # region 별로 지정 가능한 fault domain의 숫자가 다릅니다. 아래 리소스를 참조하세요.
  # https://github.com/MicrosoftDocs/azure-docs/blob/master/includes/managed-disks-common-fault-domain-region-list.md
  platform_fault_domain_count = 2
}

# **********************  NETWORK INTERFACES ********************** #
resource "azurerm_network_interface" "rke-nic" {
  name = "${var.arm-prefix}-${element(var.vm-names, count.index)}"
  location = "${azurerm_resource_group.rke-group.location}"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  network_security_group_id = "${azurerm_network_security_group.rke-secgroup.id}"
  count = "${length(var.vm-names)}"
  depends_on = ["azurerm_virtual_network.rke-vnet", "azurerm_public_ip.rke-public-ip", "azurerm_lb.rke-load-balancer"]

  ip_configuration {
    name = "ipconfig${count.index}"
    subnet_id = "${azurerm_subnet.rke-subnet.id}"
    private_ip_address_allocation = "Static"
    private_ip_address = "10.0.1.${count.index + 4}"
    load_balancer_backend_address_pools_ids = ["${azurerm_lb_backend_address_pool.rke-backend-pool.id}"]

    load_balancer_inbound_nat_rules_ids = [
      "${element(azurerm_lb_nat_rule.rke-ssh-inbound-rule.*.id, count.index)}",
      "${element(azurerm_lb_nat_rule.rke-http-inbound-rule.*.id, count.index)}",
      "${element(azurerm_lb_nat_rule.rke-https-inbound-rule.*.id, count.index)}",
    ]
  }
}

# **********************  LOAD BALANCER ********************** #
resource "azurerm_lb" "rke-load-balancer" {
  name = "${var.arm-prefix}-load-balancer"
  location = "${azurerm_resource_group.rke-group.location}"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  depends_on = ["azurerm_public_ip.rke-public-ip"]

  frontend_ip_configuration {
    name = "${var.arm-prefix}-ssh-ip-config"
    public_ip_address_id = "${azurerm_public_ip.rke-public-ip.id}"
  }
}

resource "azurerm_lb_backend_address_pool" "rke-backend-pool" {
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  loadbalancer_id = "${azurerm_lb.rke-load-balancer.id}"
  name = "${var.arm-prefix}-backend-pool"
}

# **********************  LOAD BALANCER INBOUND NAT RULES ********************** #
resource "azurerm_lb_nat_rule" "rke-ssh-inbound-rule" {
  name                           = "${var.arm-prefix}-ssh-inbound-${count.index}"
  resource_group_name            = "${azurerm_resource_group.rke-group.name}"
  loadbalancer_id                = "${azurerm_lb.rke-load-balancer.id}"
  protocol                       = "tcp"
  frontend_port                  = "6400${count.index + 1}"
  backend_port                   = 22
  frontend_ip_configuration_name = "${var.arm-prefix}-ssh-ip-config"
  count                          = "${length(var.vm-names)}"
  depends_on                     = ["azurerm_lb.rke-load-balancer"]
}

resource "azurerm_lb_nat_rule" "rke-http-inbound-rule" {
  name                           = "${var.arm-prefix}-http-inbound-${count.index}"
  resource_group_name            = "${azurerm_resource_group.rke-group.name}"
  loadbalancer_id                = "${azurerm_lb.rke-load-balancer.id}"
  protocol                       = "tcp"
  frontend_port                  = "8${count.index + 0}"
  backend_port                   = 3306
  frontend_ip_configuration_name = "${var.arm-prefix}-ssh-ip-config"
  count                          = "${length(var.vm-names)}"
  depends_on                     = ["azurerm_lb.rke-load-balancer"]
}

resource "azurerm_lb_nat_rule" "rke-https-inbound-rule" {
  name                           = "${var.arm-prefix}-https-inbound-${count.index}"
  resource_group_name            = "${azurerm_resource_group.rke-group.name}"
  loadbalancer_id                = "${azurerm_lb.rke-load-balancer.id}"
  protocol                       = "tcp"
  frontend_port                  = "44${count.index + 3}"
  backend_port                   = 9200
  frontend_ip_configuration_name = "${var.arm-prefix}-ssh-ip-config"
  count                          = "${length(var.vm-names)}"
  depends_on                     = ["azurerm_lb.rke-load-balancer"]
}

# ********************** VIRTUAL MACHINES ********************** #
resource "azurerm_virtual_machine" "rke-node-vm" {
  name                  = "${element(var.vm-names, count.index)}"
  resource_group_name   = "${azurerm_resource_group.rke-group.name}"
  location              = "${azurerm_resource_group.rke-group.location}"
  vm_size               = "Standard_DS1_v2"
  network_interface_ids = ["${element(azurerm_network_interface.rke-nic.*.id, count.index)}"]
  count                 = "${length(var.vm-names)}"
  availability_set_id   = "${azurerm_availability_set.rke-availability-set.id}"
  depends_on            = ["azurerm_availability_set.rke-availability-set", "azurerm_network_interface.rke-nic", "azurerm_storage_account.rke-storage"]

  storage_os_disk {
    name = "${element(var.vm-names, count.index)}-os-disk"
    caching = "ReadWrite"
    create_option = "FromImage"
    managed_disk_type = "Premium_LRS"
    disk_size_gb = "128"
  }

  storage_image_reference {
    publisher = "Canonical"
    offer = "UbuntuServer"
    sku = "16.04.0-LTS"
    version = "latest"
  }

  os_profile {
    computer_name = "${element(var.vm-names, count.index)}"
    admin_username = "${var.vm-admin-username}"
    admin_password = "${var.vm-admin-password}"
  }

  os_profile_linux_config {
    disable_password_authentication = false
  }

  boot_diagnostics {
    enabled = "true"
    storage_uri = "${azurerm_storage_account.rke-storage.primary_blob_endpoint}"
  }
}

resource "azurerm_virtual_machine_extension" "rke-setup-script" {
  name = "${var.arm-prefix}-${count.index}-setup-script"
  resource_group_name = "${azurerm_resource_group.rke-group.name}"
  location = "${azurerm_resource_group.rke-group.location}"
  virtual_machine_name = "${element(azurerm_virtual_machine.rke-node-vm.*.name, count.index)}"
  publisher = "Microsoft.Azure.Extensions"
  type = "CustomScript"
  type_handler_version = "2.0"
  auto_upgrade_minor_version = true
  count = "${length(var.vm-names)}"
  depends_on = ["azurerm_virtual_machine.rke-node-vm", "azurerm_lb_nat_rule.rke-ssh-inbound-rule"]

  settings = <<SETTINGS
{
  "script": "${base64encode(data.template_file.docker-deploy-script.rendered)}"
}
SETTINGS
}

# *********************** OUTPUT *********************** #

#output "endpoint-ip-address" {
#  value = "${azurerm_public_ip.rke-public-ip.ip_address}"
#}

#output "endpoint-ssh-ports" {
#  value = "${azurerm_lb_nat_rule.rke-ssh-inbound-rule.*.frontend_port}"
#}

output "sample" {
  value = <<EOF

---
nodes:
${join("\n", formatlist("  - address: ${azurerm_public_ip.rke-public-ip.ip_address}\n    user: ${var.vm-admin-username}\n    port: %s\n    role: [%s]", "${azurerm_lb_nat_rule.rke-ssh-inbound-rule.*.frontend_port}", "${var.vm-roles}"))}
services:
  etcd:
    image: quay.io/coreos/etcd:latest
  kube-api:
    image: rancher/k8s:v1.8.3-rancher2
  kube-controller:
    image: rancher/k8s:v1.8.3-rancher2
  scheduler:
    image: rancher/k8s:v1.8.3-rancher2
  kubelet:
    image: rancher/k8s:v1.8.3-rancher2
  kubeproxy:
    image: rancher/k8s:v1.8.3-rancher2
network:
  plugin: flannel
addons: |-
    ---
    apiVersion: v1
    kind: Pod
    metadata:
      name: my-nginx
      namespace: default
    spec:
      containers:
      - name: my-nginx
        image: nginx
        ports:
        - containerPort: 80
EOF
}
```

### docker-deploy-script.tpl 파일

```sh
#!/bin/bash

# Install docker daemon
curl https://releases.rancher.com/install-docker/17.03.sh | sh

# Add VM admin user to docker group
usermod -aG docker ${vm_admin_username}
```

### up.sh 파일

```sh
#!/bin/bash
wget https://github.com/rancher/rke/releases/download/v0.1.1/rke_linux-amd64
chmod +x ./rke_linux-amd64
./rke_linux-amd64 up
```

### .gitignore 파일

```text
# Compiled files
*.tfstate
*.tfstate.backup

# Module directory
.terraform/

# IDEA related directory
.idea/

# cluster.yml file (Output)
cluster.yml
```

## 3.2. ARK 클러스터 프로비져닝
